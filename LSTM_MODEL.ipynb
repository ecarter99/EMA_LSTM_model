{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "239c84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfc12e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as fh:\n",
    "    config = json.load(fh)\n",
    "    \n",
    "#feature_count = len(config['features'])\n",
    "feature_count = 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d84701db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to randomly sample the non/suicidal group windows based on #days\n",
    "    #Return:\n",
    "    #sample_encode: combination of non/suicidal randomly sampled encodings\n",
    "    #sample_lbl: combination of non/suicidal alligned random labels to encodings\n",
    "def sample_window(suicidal, nonsuicidal, batch_enc, batch_lbl, window=10):\n",
    "    sample_encode = []\n",
    "    sample_lbl = []\n",
    "    \n",
    "    for i in suicidal:\n",
    "        valid = False\n",
    "        while not valid:\n",
    "        \n",
    "            index_ls = [i for i, x in enumerate(batch_lbl[i]) if x==1 and i >= (window - 1)] #index of suicidal days\n",
    "\n",
    "            if not index_ls:\n",
    "                pos = random.randint(window ,len(batch_lbl[i]) - window - 1)\n",
    "                index_ls.append(pos)\n",
    "\n",
    "            rnd_idx = random.randint(0,len(index_ls) - 1) # random generation to choose an index from index_ls\n",
    "            index = index_ls[rnd_idx] #the index used (this is the label)\n",
    "            start = index - window - 1 #starting position of the sliding window for this particular survey run\n",
    "            \n",
    "            if (batch_enc[i][start:index+1]): break\n",
    "\n",
    "        sample_lbl.append([batch_lbl[i][index]])\n",
    "        sample_encode.append(batch_enc[i][start:index+1])\n",
    "    \n",
    "    for i in nonsuicidal:\n",
    "        valid = False\n",
    "        while not valid:\n",
    "        \n",
    "            index_ls = [i for i, x in enumerate(batch_lbl[i]) if x==0 and i >= (window - 1)] #index of suicidal days\n",
    "\n",
    "            rnd_idx = random.randint(0, len(index_ls) - 1) # random generation to choose an index from index_ls\n",
    "            index = index_ls[rnd_idx] #the index used (this is the label)\n",
    "            start = index - window - 1 #starting position of the sliding window for this particular survey run\n",
    "            \n",
    "            if (batch_enc[i][start:index+1]): break\n",
    "\n",
    "        sample_lbl.append([batch_lbl[i][index]])\n",
    "        sample_encode.append(batch_enc[i][start:index+1])\n",
    "    \n",
    "    #shuffle the lists but maintain coallation with the label\n",
    "    temp = list(zip(sample_encode, sample_lbl))\n",
    "    random.shuffle(temp)\n",
    "    shuf_encode, shuf_lbl = zip(*temp)\n",
    "    shuf_encode, shuf_lbl = list(shuf_encode), list(shuf_lbl)\n",
    "    \n",
    "    return shuf_encode, shuf_lbl\n",
    "\n",
    "#Function to Separate minibatches into non/suicidal groups to equally weigh\n",
    "#Key Question: Does this oversampling introduce too much bias?\n",
    "    #inputs:\n",
    "    #size: minibatch length to divide equally between samples\n",
    "    #Return:\n",
    "    #neg: participants with non-suicidal samples\n",
    "    #pos: participants with suicidal samples\n",
    "def oversample_classes(size):\n",
    "    indeces = random_selection(size, size)\n",
    "    pos = indeces[:int(size/2)]\n",
    "    neg = indeces[int(size/2):]\n",
    "    return pos, neg\n",
    "    \n",
    "\n",
    "#Random function with no repeats\n",
    "    #input:\n",
    "    #num_rnd = total random indeces needed (returned total list size)\n",
    "    #len_list = size of the list for random to know range for indeces\n",
    "    #Return:\n",
    "    #r_list = list of unique random indeces\n",
    "def random_selection(num_rnd, len_list):\n",
    "    rlist = []\n",
    "    for i in range(num_rnd):\n",
    "        r = random.randint(0, len_list-1)\n",
    "        while r in rlist: \n",
    "            r = random.randint(0, len_list-1)\n",
    "        rlist.append(r)\n",
    "    \n",
    "    return rlist\n",
    "            \n",
    "\n",
    "class AutismDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        # loading and preprocessing of ALL the data\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        #return later and make sure there is an offset\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # how to process just one example and one label\n",
    "        example = self.encodings[idx]\n",
    "        label = self.labels[idx]\n",
    "        return example, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def custom_collate_fn(minibatch):\n",
    "    batch_examples = list([list(e[0]) for e in minibatch]) #convert encodings to list\n",
    "    label_examples = list([list(e[1]) for e in minibatch]) #convert labels to list (need to track along with encod)\n",
    "    \n",
    "    max_len = max([len(e) for e in batch_examples]) #get the participant with most surveys\n",
    "    \n",
    "    mask = [] #setup the mask structure for all participants\n",
    "    for e in range(len(batch_examples)): #loop through all the participants\n",
    "        e_mask = [1 for i in range(len(batch_examples[e]))] #initialize this participants individual mask\n",
    "        while len(batch_examples[e]) < max_len: #looping over the longest number of surveys to mask/pad\n",
    "            e_mask.append(0) #adding to the mask for the particiapnt\n",
    "            label_examples[e].append(0) #padding label to track before collating\n",
    "            batch_examples[e].append([0 for i in range(feature_count)]) #padding the participants survey data\n",
    "            \n",
    "        mask.append(e_mask) #adding the participants mask to the entirety of the mask data\n",
    "    \n",
    "    #randomly select the 2 classes of participants\n",
    "    negative, positive = oversample_classes(size=len(label_examples))\n",
    "    \n",
    "    #randomly sample x days within the classes\n",
    "    samp_batch, samp_lbl = sample_window(positive, negative, batch_examples, label_examples, config['window_size'])\n",
    "    \n",
    "    batch_examples = [torch.tensor(e) for e in samp_batch] #converting the endcodings to tensors\n",
    "    batch_labels = [torch.tensor(e).long() for e in samp_lbl] #converting labels to tensors\n",
    "    \n",
    "    return (batch_examples, batch_labels, mask)\n",
    "\n",
    "def validate_collate(minibatch):\n",
    "    batch_examples = list([list(e[0]) for e in minibatch]) #convert encodings to list\n",
    "    label_examples = list([list(e[1]) for e in minibatch]) #convert labels to list (need to track along with encod)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "373d2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_encodings(x, val_participants):\n",
    "    x = dataframe.loc[:, ('energy_levels','motivation','productivity','illness','food_health',\n",
    "                                      'physical_activity','leisure_time','negative_feelings','reduce_negativity',\n",
    "                                      'positive_feelings','increase_positive','enjoy_moment','show_feelings',\n",
    "                                      'accepting_feelings','fault_feeling','feel_better','feelings_last','stressed',\n",
    "                                      'stress_amount','stress_management','stress_interference','face_interaction',\n",
    "                                      'digital_interaction','person_connection','digital_connection',\n",
    "                                      'desire_interaction','feeling_support','spiritual_connection','number_naps',\n",
    "                                      'napping_time','days','Response_Gap','Next_Gap',\n",
    "                                      'suicide_thoughts','Recipient_First_Name','Prescribed_Group')]\n",
    "    \n",
    "    x[['stress_amount','stress_management',\n",
    "       'stress_interference','napping_time']] = x[['stress_amount','stress_management',\n",
    "                                                   'stress_interference','napping_time']].fillna(value=0)\n",
    "    x = x.dropna()\n",
    "    \n",
    "    x['reduce_negativity'] = x['reduce_negativity'].map({'Yes':1.0,'No':0.0})\n",
    "    x['increase_positive'] = x['increase_positive'].map({'Yes':1.0,'No':0.0})\n",
    "    x['enjoy_moment'] = x['enjoy_moment'].map({'Yes':1.0,'No':0.0})\n",
    "    x['show_feelings'] = x['show_feelings'].map({'Yes':1.0,'No':0.0})\n",
    "    x['accepting_feelings'] = x['accepting_feelings'].map({'Yes':1.0,'No':0.0})\n",
    "    x['fault_feeling'] = x['fault_feeling'].map({'Yes':1.0,'No':0.0})\n",
    "    x['feel_better'] = x['feel_better'].map({'Yes':1.0,'No':0.0})\n",
    "    x['feelings_last'] = x['feelings_last'].map({'Yes':1.0,'No':0.0})\n",
    "    x['stressed'] = x['stressed'].map({'Yes':1.0,'No':0.0})\n",
    "    x['suicide_thoughts'] = x['suicide_thoughts'].map({'Yes':1.0,'No':0.0})\n",
    "    x = x.drop(['napping_time'], axis=1)\n",
    "    \n",
    "    onehot_group = pd.get_dummies(x['Prescribed_Group'])\n",
    "    x = x.drop(['Prescribed_Group'],axis=1)\n",
    "    x = x.join(onehot_group)\n",
    "    \n",
    "    reshaped = []\n",
    "    labeled = []\n",
    "    \n",
    "    val_enc = []\n",
    "    val_lbl = []\n",
    "    for part in x.Recipient_First_Name.unique():\n",
    "        queried = x.query('Recipient_First_Name==@part')\n",
    "        \n",
    "        if part in val_participants:\n",
    "            val_lbl.append(queried.suicide_thoughts.values[1:])\n",
    "            queried = queried.drop('Recipient_First_Name',axis=1)\n",
    "            val_enc.append(queried.values[:-1])\n",
    "        else:\n",
    "            labeled.append(queried.suicide_thoughts.values[1:])\n",
    "            queried = queried.drop('Recipient_First_Name',axis=1)\n",
    "            reshaped.append(queried.values[:-1])\n",
    "        \n",
    "    return reshaped, labeled, val_enc, val_lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "866ffc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMmodel(nn.Module):\n",
    "    def __init__(self, num_features, hidden_layer_size, num_layers, output_size, bidirectional=False, p_dropout=0.0):\n",
    "        super().__init__()\n",
    "           \n",
    "        self.num_features = num_features\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.output_size = output_size\n",
    "        self.p_dropout = p_dropout\n",
    "        self.hidden_layer_size = hidden_layer_size*(int(self.bidirectional)+1)\n",
    "        self.lstm = nn.LSTM(input_size=self.num_features, hidden_size=hidden_layer_size,\n",
    "                            num_layers=self.num_layers, batch_first=True, dropout=self.p_dropout,\n",
    "                            bidirectional=self.bidirectional)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.hidden_layer_size, self.hidden_layer_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(self.hidden_layer_size//2, self.output_size)\n",
    "                )\n",
    "\n",
    "    # \n",
    "    def forward(self, x):\n",
    "        bs, seq_len, _ = x.size()\n",
    "        hidden_cell = self.reset_forward(bs, x.device)\n",
    "        output, _ = self.lstm(x, hidden_cell)\n",
    "        final_hidden_representation = output[:,-1]\n",
    "        out = self.classifier(final_hidden_representation)\n",
    "        return out\n",
    "\n",
    "    # Function to reset the initial vector to 0's -> we don't want to muddy up the classification\n",
    "    def reset_forward(self, bs, device='cpu'):\n",
    "        return (torch.zeros((1+self.bidirectional)*self.num_layers,bs,int(self.hidden_layer_size/(1+self.bidirectional))).float().to(device),\n",
    "                torch.zeros((1+self.bidirectional)*self.num_layers,bs,int(self.hidden_layer_size/(1+self.bidirectional))).float().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67f0bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LSTM():\n",
    "    lstm = LSTMmodel(num_features=feature_count, hidden_layer_size=128, num_layers=1, output_size=2, bidirectional=True, p_dropout=0)\n",
    "\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "    rate_learning = 1e-4\n",
    "    optim = torch.optim.Adam(lstm.parameters(), lr=rate_learning, weight_decay=1e-3)\n",
    "\n",
    "    epochs = 100\n",
    "\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "\n",
    "        for encoding, label, mask in train_loader:\n",
    "            output = lstm(torch.stack(encoding).float())\n",
    "            loss = loss_function(output, torch.cat(label).long()) #if i pull out the 'labels' here...what can I replace it with?\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            running_loss += float(loss)\n",
    "            \n",
    "    testset = AutismDataset(validation_encoding, validation_lables)\n",
    "    testloader = torch.utils.data.DataLoader(dataset,collate_fn=custom_collate_fn,shuffle=True,batch_size=5)\n",
    "\n",
    "    torch.save({'state_dict': lstm.state_dict(),\n",
    "                        'optimizer' : optim.state_dict(),\n",
    "                       }, 'first_model.pth')\n",
    "\n",
    "    dataiter = iter(testloader)\n",
    "    test_encodings, test_labels, test_mask = next(dataiter)\n",
    "\n",
    "    outputs = lstm(torch.stack(test_encodings).float())\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels, mask = data\n",
    "            outputs = lstm(torch.stack(images).float())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += torch.tensor(labels).size(0)\n",
    "            labels = torch.cat(labels).long()\n",
    "            #print('prediction')\n",
    "            #print(predicted)\n",
    "            #print('label')\n",
    "            #print(labels)\n",
    "            correct += float((predicted == labels).sum().item())\n",
    "\n",
    "    print('Accuracy of the network: %f %%' % (\n",
    "        100 * correct / total))\n",
    "    \n",
    "    return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93c617b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_participants(x):\n",
    "    names = x.Recipient_First_Name.unique()\n",
    "    sampling = random.sample(list(names),3)\n",
    "    return sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfe6c8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 75.000000 %\n",
      "Accuracy of the network: 86.250000 %\n",
      "Accuracy of the network: 79.746835 %\n",
      "Accuracy of the network: 89.873418 %\n",
      "Accuracy of the network: 82.278481 %\n",
      "Accuracy of the network: 73.417722 %\n",
      "Accuracy of the network: 86.075949 %\n",
      "Accuracy of the network: 86.075949 %\n",
      "Accuracy of the network: 73.417722 %\n",
      "Accuracy of the network: 87.500000 %\n",
      "Accuracy of the network: 83.544304 %\n",
      "Accuracy of the network: 81.250000 %\n",
      "Accuracy of the network: 89.873418 %\n",
      "Accuracy of the network: 84.810127 %\n",
      "Accuracy of the network: 82.500000 %\n",
      "Accuracy of the network: 81.012658 %\n",
      "Accuracy of the network: 88.607595 %\n",
      "Accuracy of the network: 86.075949 %\n",
      "Accuracy of the network: 82.500000 %\n",
      "Accuracy of the network: 86.075949 %\n"
     ]
    }
   ],
   "source": [
    "#loop through samples:\n",
    "accuracies = []\n",
    "samples = []\n",
    "dataframe = pd.read_csv(config['data'])\n",
    "for i in range(config['validation_loop']):\n",
    "    samp = sample_participants(dataframe)\n",
    "    samples.append(samp)\n",
    "    encodings, labels, validation_encoding, validation_lables = preprocess_encodings(dataframe,samp)\n",
    "    dataset = AutismDataset(encodings,labels)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset,collate_fn=custom_collate_fn,shuffle=True,batch_size=5)\n",
    "    \n",
    "    accuracies.append(run_LSTM())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34ea704f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4CElEQVR4nO3deVyVZf7/8fcB5QgIuIMogriEGJm44DZqi7tGuWuuWDk5U+KUGg2amoropI425TRfQ0cNqcxlcix3zYkcBbFyy0xFU7Sp5LiiwP37o59nOgMuR8ED3q/n43Eeda77uq/7c/GYR+c9171ZDMMwBAAAYCJuri4AAADgXiMAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0yEAAQAA0ynj6gJKovz8fJ06dUo+Pj6yWCyuLgcAANwGwzB0/vx5BQYGys3t5ms8BKBCnDp1SkFBQa4uAwAA3IETJ06oZs2aN+1DACqEj4+PpF/+gL6+vi6uBgAA3A6bzaagoCD77/jNEIAKcf20l6+vLwEIAIBS5nYuX+EiaAAAYDoEIAAAYDoEIAAAYDoEIAAAYDoEIAAAYDoEIAAAYDoEIAAAYDoEIAAAYDouDUDnz59XbGysgoOD5enpqVatWmnXrl327YZhaNKkSQoMDJSnp6fat2+vffv23XLcFStWKDw8XFarVeHh4Vq5cmVxTgMAAJQyLg1AzzzzjDZs2KAlS5boq6++UseOHfX444/r+++/lyTNnDlTs2fP1ptvvqldu3YpICBAHTp00Pnz5284Zmpqqvr166fBgwdr7969Gjx4sPr27audO3feq2kBAIASzmIYhuGKA1++fFk+Pj5avXq1unXrZm9/+OGH1b17d73++usKDAxUbGysxo8fL0nKycmRv7+/EhMTNXLkyELH7devn2w2m9atW2dv69y5sypWrKjk5ORC98nJyVFOTo79+/V3iWRnZ/MqDAAASgmbzSY/P7/b+v122QpQbm6u8vLyVK5cOYd2T09P7dixQ0ePHlVWVpY6duxo32a1WtWuXTt9/vnnNxw3NTXVYR9J6tSp0033SUhIkJ+fn/3Dm+ABALi/uSwA+fj4qGXLlnr99dd16tQp5eXlaenSpdq5c6dOnz6trKwsSZK/v7/Dfv7+/vZthcnKynJ6n7i4OGVnZ9s/J06cuIuZAQCAks6lb4NfsmSJYmJiVKNGDbm7uysyMlIDBw5Uenq6vc//vtHVMIxbvuXV2X2sVqusVusdzADAvXLp0iUdPHjwrse5fPmyjh07ppCQEHl6ehZBZVJYWJi8vLyKZCwA94ZLA1CdOnW0bds2Xbx4UTabTdWrV1e/fv1Uu3ZtBQQESPplRad69er2fc6ePVtghefXAgICCqz23GofACXfwYMH1aRJE1eXUai0tDRFRka6ugwATnBpALrO29tb3t7e+vnnn/Xpp59q5syZ9hC0YcMGNW7cWJJ09epVbdu2TYmJiTccq2XLltqwYYPGjBljb1u/fr1atWpV7PMAUHzCwsKUlpZ21+McOHBAgwYN0tKlS9WgQYMiqOyX2gCULi4NQJ9++qkMw9ADDzygb7/9VmPHjtUDDzyg4cOHy2KxKDY2VtOnT1e9evVUr149TZ8+XV5eXho4cKB9jCFDhqhGjRpKSEiQJI0ePVpt27ZVYmKioqOjtXr1am3cuFE7duxw1TQBFAEvL68iXWVp0KABqzaAibk0AGVnZysuLk4nT55UpUqV1KtXL02bNk1ly5aVJI0bN06XL1/WqFGj9PPPPysqKkrr16+Xj4+PfYzMzEy5uf33Wu5WrVpp+fLlio+P14QJE1SnTh2lpKQoKirqns8PAACUTC57DlBJ5sxzBACULunp6WrSpAnX7QD3oVLxHCAAAABXIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTIQABAADTcWkAys3NVXx8vGrXri1PT0+FhoZqypQpys/Pt/exWCyFfmbNmnXDcRctWlToPleuXLkX0wIAACVcGVcePDExUQsWLNDixYvVsGFD7d69W8OHD5efn59Gjx4tSTp9+rTDPuvWrdOIESPUq1evm47t6+urQ4cOObSVK1euaCcAAABKJZcGoNTUVEVHR6tbt26SpJCQECUnJ2v37t32PgEBAQ77rF69Wo888ohCQ0NvOrbFYimw743k5OQoJyfH/t1ms93uFAAAQCnk0lNgbdq00aZNm/TNN99Ikvbu3asdO3aoa9euhfY/c+aM1q5dqxEjRtxy7AsXLig4OFg1a9ZU9+7dtWfPnhv2TUhIkJ+fn/0TFBR0ZxMCAAClgksD0Pjx4zVgwACFhYWpbNmyaty4sWJjYzVgwIBC+y9evFg+Pj7q2bPnTccNCwvTokWLtGbNGiUnJ6tcuXJq3bq1Dh8+XGj/uLg4ZWdn2z8nTpy467kBAICSy6WnwFJSUrR06VK99957atiwoTIyMhQbG6vAwEANHTq0QP93331XTz/99C2v5WnRooVatGhh/966dWtFRkZq/vz5mjdvXoH+VqtVVqv17icEAABKBZcGoLFjx+qVV15R//79JUkRERE6fvy4EhISCgSgzz77TIcOHVJKSorTx3Fzc1OzZs1uuAIEAADMxaWnwC5duiQ3N8cS3N3dHW6Dv27hwoVq0qSJGjVq5PRxDMNQRkaGqlevfse1AgCA+4dLV4B69OihadOmqVatWmrYsKH27Nmj2bNnKyYmxqGfzWbTBx98oDfeeKPQcYYMGaIaNWooISFBkjR58mS1aNFC9erVk81m07x585SRkaG//OUvxT4nAABQ8rk0AM2fP18TJkzQqFGjdPbsWQUGBmrkyJGaOHGiQ7/ly5fLMIwbXhydmZnpsJJ07tw5Pffcc8rKypKfn58aN26s7du3q3nz5sU6HwAAUDpYDMMwXF1ESWOz2eTn56fs7Gz5+vq6uhwARSg9PV1NmjRRWlqaIiMjXV0OgCLkzO837wIDAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmU8bVBQC4vx0+fFjnz593dRl2Bw4ccPhnSeHj46N69eq5ugzANAhAAIrN4cOHVb9+fVeXUahBgwa5uoQCvvnmG0IQcI8QgAAUm+srP0uXLlWDBg1cXM0vLl++rGPHjikkJESenp6uLkfSL6tRgwYNKlErZcD9jgAEoNg1aNBAkZGRri7DrnXr1q4uAYCLcRE0AAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHQIQAAAwHZcGoNzcXMXHx6t27dry9PRUaGiopkyZovz8fHufYcOGyWKxOHxatGhxy7FXrFih8PBwWa1WhYeHa+XKlcU5FQAAUIqUceXBExMTtWDBAi1evFgNGzbU7t27NXz4cPn5+Wn06NH2fp07d1ZSUpL9u4eHx03HTU1NVb9+/fT666/rqaee0sqVK9W3b1/t2LFDUVFRxTYfAABQOrg0AKWmpio6OlrdunWTJIWEhCg5OVm7d+926Ge1WhUQEHDb486dO1cdOnRQXFycJCkuLk7btm3T3LlzlZycXKB/Tk6OcnJy7N9tNtudTAcAAJQSLj0F1qZNG23atEnffPONJGnv3r3asWOHunbt6tBv69atqlatmurXr69nn31WZ8+evem4qamp6tixo0Nbp06d9PnnnxfaPyEhQX5+fvZPUFDQXcwKAACUdC5dARo/fryys7MVFhYmd3d35eXladq0aRowYIC9T5cuXdSnTx8FBwfr6NGjmjBhgh599FGlpaXJarUWOm5WVpb8/f0d2vz9/ZWVlVVo/7i4OP3hD3+wf7fZbIQgAADuYy4NQCkpKVq6dKnee+89NWzYUBkZGYqNjVVgYKCGDh0qSerXr5+9/4MPPqimTZsqODhYa9euVc+ePW84tsVicfhuGEaBtuusVusNwxQAALj/uDQAjR07Vq+88or69+8vSYqIiNDx48eVkJBgD0D/q3r16goODtbhw4dvOG5AQECB1Z6zZ88WWBUCAADm5NJrgC5duiQ3N8cS3N3dHW6D/18//vijTpw4oerVq9+wT8uWLbVhwwaHtvXr16tVq1Z3VzAAALgvuHQFqEePHpo2bZpq1aqlhg0bas+ePZo9e7ZiYmIkSRcuXNCkSZPUq1cvVa9eXceOHdOrr76qKlWq6KmnnrKPM2TIENWoUUMJCQmSpNGjR6tt27ZKTExUdHS0Vq9erY0bN2rHjh0umScAAChZXBqA5s+frwkTJmjUqFE6e/asAgMDNXLkSE2cOFHSL6tBX331lf7+97/r3Llzql69uh555BGlpKTIx8fHPk5mZqbDSlKrVq20fPlyxcfHa8KECapTp45SUlJ4BhAAAJAkWQzDMFxdREljs9nk5+en7Oxs+fr6urocoNRKT09XkyZNlJaWpsjISFeXU2LxdwKKhjO/37wLDAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmA4BCAAAmI5LnwQN4P5myb2ixgFu8jz3jXSK/791I57nvlHjADdZcq+4uhTANAhAAIpNuQuZSh9ZXto+Utru6mpKrgaS0keW14ELmZJ4aTNwLxCAABSbK+VrKfKvF7Rs2TI1CAtzdTkl1oGDB/X0009rYddari4FMA0CEIBiY5Qppz1Z+bpcob4U+LCryymxLmfla09Wvowy5VxdCmAanJQHAACmQwACAACmQwACAACmQwACAACmQwACANzUokWLZLFYZLFYtHXr1gLbDcNQ3bp1ZbFY1L59+3teX1Gw2Wz64x//qPr168vLy0s1atRQnz59tG/fPod+GRkZ6tatm2rVqiVPT09VqlRJLVu21NKlS2/rOB999JEGDBigunXrytPTUyEhIXr66ad1+PDhAn2vXr2qiRMnqnbt2vLw8FBwcLDi4uJ0+fLlIpmz2XEXGADgtvj4+GjhwoUFQs62bdt05MgR+fj4uKawItCjRw/t3r1bkyZNUtOmTXXy5ElNmTJFLVu21FdffaXg4GBJ0rlz5xQUFKQBAwaoRo0aunjxopYtW6bBgwfr2LFjio+Pv+lxEhMTFRAQoD/+8Y8KDQ3ViRMnNH36dEVGRuqLL75Qw4YN7X0HDBigf/7zn5o4caKaNWum1NRUTZ06Vfv27dOaNWuK9e9hCgYKyM7ONiQZ2dnZri4FKNXS0tIMSUZaWpqrSynRSvrfKSkpyZBkPPPMM4anp2eB/zYOGjTIaNmypdGwYUOjXbt2rinyLhw+fNiQZMTHxzu0f/7554YkY/bs2bccIyoqyggKCrplvzNnzhRo+/77742yZcsaI0aMsLelpqYakow33njDoe/06dMNScb69etveSwzcub3m1NgAIDbMmDAAElScnKyvS07O1srVqxQTExMoftcvXpVU6dOVVhYmKxWq6pWrarhw4frhx9+cOiXkpKijh07qnr16vL09FSDBg30yiuv6OLFiw79hg0bpvLly+vbb79V165dVb58eQUFBemll15STk7OHc2rbNmykiQ/Pz+H9goVKkiSypW79fOZqlSpojJlbn1SpVq1agXaAgMDVbNmTZ04ccLe9q9//UuS1LVrV4e+3bt3lyStWLHilsfCzRGAAAC3xdfXV71799a7775rb0tOTpabm5v69etXoH9+fr6io6M1Y8YMDRw4UGvXrtWMGTO0YcMGtW/f3uFalsOHD6tr165auHChPvnkE8XGxur9999Xjx49Cox77do1PfHEE3rssce0evVqxcTEaM6cOUpMTHToN2zYMFksFh07duym8woODlZ0dLTmzJmjLVu26MKFCzp48KBefPFF1apVS/379y90brm5ufrhhx/01ltv6dNPP9X48eNv9Scs1Hfffafjx487nP66evWqJMlqtTr0vf79yy+/vKNj4VfuwYpUqcMpMKBolPRTOyVFSf87XT8FtmvXLmPLli2GJOPrr782DMMwmjVrZgwbNswwDKPAKbDk5GRDkrFixQqH8Xbt2mVIMt56661Cj5efn29cu3bN2LZtmyHJ2Lt3r33b0KFDDUnG+++/77BP165djQceeMChLSYmxnB3dzeOHTt2yzlevXrVePbZZw1J9s9DDz1kHD16tND+I0eOtPfz8PC44Vxu5dq1a0b79u0NX19fIzMz096+atUqQ5KxZMkSh/4LFy40JBn169e/o+Pd7zgFBgAoFu3atVOdOnX07rvv6quvvtKuXbtuePrr448/VoUKFdSjRw/l5ubaPw8//LACAgIc7ij77rvvNHDgQAUEBMjd3V1ly5ZVu3btJEkHDhxwGNdisRRYGXrooYd0/Phxh7aFCxcqNzfXfgHzzTz//PNasWKF5syZo23btiklJUUeHh569NFHC4wrSa+++qp27dqltWvXKiYmRr///e/1pz/96ZbH+TXDMDRixAh99tln+vvf/66goCD7ti5duqhu3boaP368NmzYoHPnzumTTz7Rq6++Knd3d7m58fN9t7gLDABw2ywWi4YPH6558+bpypUrql+/vn7zm98U2vfMmTM6d+6cPDw8Ct3+n//8R5J04cIF/eY3v1G5cuU0depU+63oJ06cUM+ePQvc9u3l5VXguhyr1aorV67c0Zw++eQTLVy4UB988IF69+5tb+/YsaNCQkI0adIkJSUlOexTq1Yt1ar1y8trr1+nExcXp6FDh6pq1aq3PKZhGHrmmWe0dOlSLV68WNHR0Q7bPTw8tG7dOg0ePFgdO3aUJHl7e2v69Ol6/fXXVaNGjTuaK/6LAAQAcMqwYcM0ceJELViwQNOmTbthvypVqqhy5cr65JNPCt1+/bb5zZs369SpU9q6dat91Uf65ZbzeyEjI0OS1KxZM4f2ChUqqG7duvr6669vOUbz5s21YMECfffdd7cMQNfDT1JSkhYuXKhBgwYV2q9u3bpKTU3V999/r59++kl16tRRdna2Ro8erbZt297e5HBDBCAAgFNq1KihsWPH6uDBgxo6dOgN+3Xv3l3Lly9XXl6eoqKibtjPYrFIKnjB71//+teiKfgWAgMDJUlffPGFw+myH3/8Ud98840ee+yxW46xZcsWubm5KTQ09Kb9DMPQs88+q6SkJP31r3/V8OHDbzl2jRo17Cs+8fHx8vb21ogRI265H26OAAQAcNqMGTNu2ad///5atmyZunbtqtGjR6t58+YqW7asTp48qS1btig6OlpPPfWUWrVqpYoVK+q3v/2tXnvtNZUtW1bLli3T3r1776rGESNGaPHixTpy5MhNrwPq2bOnJk6cqOeff14nT55UZGSkTp8+rVmzZunSpUsaPXq0ve9zzz0nX19fNW/eXP7+/vrPf/6jDz74QCkpKRo7dqzD6k9hx3/xxRe1cOFCxcTEKCIiQl988YW9v9VqVePGje3fZ86cqYCAANWqVUtnzpzR+++/r1WrVmnJkiWcAisCBCAAQLFwd3fXmjVr9Oc//1lLlixRQkKCypQpo5o1a6pdu3aKiIiQJFWuXFlr167VSy+9pEGDBsnb21vR0dFKSUlRZGTkHR8/Ly9PeXl5Mgzjpv3Kly+vL774QtOmTdOCBQt08uRJVapUSY0bN9bbb7+tFi1a2Pu2bNlSSUlJWrx4sc6dO6fy5curUaNGWrJkSYFTWYUd/x//+Ick6d1333V4nID0y+34v75l/8qVK5oyZYpOnjwpT09PtWjRQlu3br3hNVdwjsW41f8yTMhms8nPz0/Z2dny9fV1dTlAqZWenq4mTZooLS3trn7I7nf8nYCi4czvN/fRAQAA0yEAAQAA0yEAAQAA0yEAAQAA03E6AIWEhGjKlCnKzMwsjnoAAACKndMB6KWXXtLq1asVGhqqDh06aPny5crJySmO2gAAAIqF0wHohRdeUFpamtLS0hQeHq4XX3xR1atX1+9//3ulp6cXR40AAABF6o6vAWrUqJH+/Oc/6/vvv9drr72m//u//1OzZs3UqFEjvfvuu7d88BQAAICr3PGToK9du6aVK1cqKSlJGzZsUIsWLTRixAidOnVKf/zjH7Vx40a99957RVkrAABAkXA6AKWnpyspKUnJyclyd3fX4MGDNWfOHIWFhdn7dOzYkTfVAgCAEsvpANSsWTN16NBBb7/9tp588kmVLVu2QJ/w8HD179+/SAoEAAAoak5fA/Tdd9/pk08+UZ8+fQoNP5Lk7e2tpKSkW46Vm5ur+Ph41a5dW56engoNDdWUKVOUn58v6ZfTbOPHj1dERIS8vb0VGBioIUOG6NSpUzcdd9GiRbJYLAU+V65ccXa6AADgPuT0CtDZs2eVlZWlqKgoh/adO3fK3d1dTZs2ve2xEhMTtWDBAi1evFgNGzbU7t27NXz4cPn5+Wn06NG6dOmS0tPTNWHCBDVq1Eg///yzYmNj9cQTT2j37t03HdvX11eHDh1yaCtXrtztTxQAANy3nA5Av/vd7zRu3LgCAej7779XYmKidu7cedtjpaamKjo6Wt26dZP0y0MWk5OT7eHGz89PGzZscNhn/vz5at68uTIzM1WrVq0bjm2xWBQQEHBbdeTk5Dg8y8hms932HAAAQOnj9Cmw/fv3KzIyskB748aNtX//fqfGatOmjTZt2qRvvvlGkrR3717t2LFDXbt2veE+2dnZslgsqlChwk3HvnDhgoKDg1WzZk11795de/bsuWHfhIQE+fn52T9BQUFOzQMAAJQuTgcgq9WqM2fOFGg/ffq0ypRxbkFp/PjxGjBggMLCwlS2bFk1btxYsbGxGjBgQKH9r1y5oldeeUUDBw6Ur6/vDccNCwvTokWLtGbNGiUnJ6tcuXJq3bq1Dh8+XGj/uLg4ZWdn2z8nTpxwah4AAKB0cfoUWIcOHRQXF6fVq1fLz89PknTu3Dm9+uqr6tChg1NjpaSkaOnSpXrvvffUsGFDZWRkKDY2VoGBgRo6dKhD32vXrql///7Kz8/XW2+9ddNxW7RooRYtWti/t27dWpGRkZo/f77mzZtXoL/VapXVanWqdgAAUHo5HYDeeOMNtW3bVsHBwWrcuLEkKSMjQ/7+/lqyZIlTY40dO1avvPKK/Zb5iIgIHT9+XAkJCQ4B6Nq1a+rbt6+OHj2qzZs333T1pzBubm5q1qzZDVeAAACAuTgdgGrUqKEvv/xSy5Yt0969e+Xp6anhw4drwIABN7wt/kYuXbokNzfHs3Du7u722+Cl/4afw4cPa8uWLapcubKzJcswDGVkZCgiIsLpfQEAwP3njl6F4e3treeee+6uD96jRw9NmzZNtWrVUsOGDbVnzx7Nnj1bMTExkn55TlDv3r2Vnp6ujz/+WHl5ecrKypIkVapUSR4eHpKkIUOGqEaNGkpISJAkTZ48WS1atFC9evVks9k0b948ZWRk6C9/+ctd1wwAAEq/O34X2P79+5WZmamrV686tD/xxBO3Pcb8+fM1YcIEjRo1SmfPnlVgYKBGjhypiRMnSpJOnjypNWvWSJIefvhhh323bNmi9u3bS5IyMzMdVpLOnTun5557TllZWfLz81Pjxo21fft2NW/e/A5mCgAA7jcWw8nXtn/33Xd66qmn9NVXX8lisdjf+m6xWCRJeXl5RV/lPWaz2eTn56fs7GynrzcC8F/p6elq0qSJ0tLSCn18Bn7B3wkoGs78fjt9G/zo0aNVu3ZtnTlzRl5eXtq3b5+2b9+upk2bauvWrXdaMwAAwD3j9Cmw1NRUbd68WVWrVpWbm5vc3NzUpk0bJSQk6MUXX7zpAwcBAABKAqdXgPLy8lS+fHlJUpUqVewvJg0ODi7w7i0AAICSyOkVoAcffFBffvmlQkNDFRUVpZkzZ8rDw0PvvPOOQkNDi6NGAACAIuV0AIqPj9fFixclSVOnTlX37t31m9/8RpUrV1ZKSkqRFwgAAFDUnA5AnTp1sv97aGio9u/fr59++kkVK1a03wkGAABQkjl1DVBubq7KlCmjr7/+2qG9UqVKhB8AAFBqOBWAypQpo+Dg4PviWT8AAMC8nL4LLD4+XnFxcfrpp5+Kox4AAIBi5/Q1QPPmzdO3336rwMBABQcHy9vb22F7enp6kRUHAABQHJwOQE8++WQxlAEAAHDvOB2AXnvtteKoAwAA4J5x+hogAACA0s7pFSA3N7eb3vLOHWIAAKCkczoArVy50uH7tWvXtGfPHi1evFiTJ08ussIAAACKi9MBKDo6ukBb79691bBhQ6WkpGjEiBFFUhgAAEBxKbJrgKKiorRx48aiGg4AAKDYFEkAunz5subPn6+aNWsWxXAAAADFyulTYP/70lPDMHT+/Hl5eXlp6dKlRVocgNLt0qVLkkrWA1IvX76sY8eOKSQkRJ6enq4uR5J04MABV5cAmI7TAWjOnDkOAcjNzU1Vq1ZVVFSUKlasWKTFASjdDh48KEl69tlnXVxJ6eDj4+PqEgDTcDoADRs2rBjKAHA/uv7k+LCwMHl5ebm2mP/vwIEDGjRokJYuXaoGDRq4uhw7Hx8f1atXz9VlAKbhdABKSkpS+fLl1adPH4f2Dz74QJcuXdLQoUOLrDgApVuVKlX0zDPPuLqMQjVo0ECRkZGuLgOAizh9EfSMGTNUpUqVAu3VqlXT9OnTi6QoAACA4uR0ADp+/Lhq165doD04OFiZmZlFUhQAAEBxcjoAVatWTV9++WWB9r1796py5cpFUhQAAEBxcjoA9e/fXy+++KK2bNmivLw85eXlafPmzRo9erT69+9fHDUCAAAUKacvgp46daqOHz+uxx57TGXK/LJ7fn6+hgwZwjVAAACgVHA6AHl4eCglJUVTp05VRkaGPD09FRERoeDg4OKoDwAAoMg5HYCuq1evHs+sAAAApZLT1wD17t1bM2bMKNA+a9asAs8GAgAAKImcDkDbtm1Tt27dCrR37txZ27dvL5KiAAAAipPTAejChQvy8PAo0F62bFnZbLYiKQoAAKA4OR2AHnzwQaWkpBRoX758ucLDw4ukKAAAgOLk9EXQEyZMUK9evXTkyBE9+uijkqRNmzbpvffe04cffljkBQIAABQ1pwPQE088oVWrVmn69On68MMP5enpqUaNGmnz5s3y9fUtjhoBAACK1B3dBt+tWzf7hdDnzp3TsmXLFBsbq7179yovL69ICwQAAChqTl8DdN3mzZs1aNAgBQYG6s0331TXrl21e/fuoqwNAACgWDi1AnTy5EktWrRI7777ri5evKi+ffvq2rVrWrFiBRdAAwCAUuO2V4C6du2q8PBw7d+/X/Pnz9epU6c0f/784qwNAACgWNz2CtD69ev14osv6vnnn+cVGAAAoFS77RWgzz77TOfPn1fTpk0VFRWlN998Uz/88MNdHTw3N1fx8fGqXbu2PD09FRoaqilTpig/P9/exzAMTZo0SYGBgfL09FT79u21b9++W459/bSc1WpVeHi4Vq5ceVe1AgCA+8dtB6CWLVvqb3/7m06fPq2RI0dq+fLlqlGjhvLz87VhwwadP3/e6YMnJiZqwYIFevPNN3XgwAHNnDlTs2bNcji1NnPmTM2ePVtvvvmmdu3apYCAAHXo0OGmx0tNTVW/fv00ePBg7d27V4MHD1bfvn21c+dOp2sEAAD3H4thGMad7nzo0CEtXLhQS5Ys0blz59ShQwetWbPmtvfv3r27/P39tXDhQntbr1695OXlpSVLlsgwDAUGBio2Nlbjx4+XJOXk5Mjf31+JiYkaOXJkoeP269dPNptN69ats7d17txZFStWVHJy8i3rstls8vPzU3Z2Ns82Au4z6enpatKkidLS0hQZGenqcgAUIWd+v+/4NnhJeuCBBzRz5kydPHnytoLF/2rTpo02bdqkb775RpK0d+9e7dixQ127dpUkHT16VFlZWerYsaN9H6vVqnbt2unzzz+/4bipqakO+0hSp06dbrhPTk6ObDabwwcAANy/7uhBiP/L3d1dTz75pJ588kmn9hs/fryys7MVFhYmd3d35eXladq0aRowYIAkKSsrS5Lk7+/vsJ+/v7+OHz9+w3GzsrIK3ef6eP8rISFBkydPdqp2AABQet3VCtDdSklJ0dKlS/Xee+8pPT1dixcv1p/+9CctXrzYoZ/FYnH4bhhGgbb/5cw+cXFxys7Otn9OnDhxB7MBAAClRZGsAN2psWPH6pVXXlH//v0lSRERETp+/LgSEhI0dOhQBQQESPplRad69er2/c6ePVtghefXAgICCqz23Gwfq9Uqq9V6t9MBAAClhEtXgC5duiQ3N8cS3N3d7bfB165dWwEBAdqwYYN9+9WrV7Vt2za1atXqhuO2bNnSYR/pl+cY3WwfAABgHi5dAerRo4emTZumWrVqqWHDhtqzZ49mz56tmJgYSb+cxoqNjdX06dNVr1491atXT9OnT5eXl5cGDhxoH2fIkCGqUaOGEhISJEmjR49W27ZtlZiYqOjoaK1evVobN27Ujh07XDJPAABQsrg0AM2fP18TJkzQqFGjdPbsWQUGBmrkyJGaOHGivc+4ceN0+fJljRo1Sj///LOioqK0fv16+fj42PtkZmY6rCS1atVKy5cvV3x8vCZMmKA6deooJSVFUVFR93R+AACgZLqr5wDdr3gOEHD/4jlAwP3rnj0HCAAAoDQiAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANMhAAEAANNxaQAKCQmRxWIp8Pnd734nSYVus1gsmjVr1g3HXLRoUaH7XLly5V5NCwAAlHBlXHnwXbt2KS8vz/7966+/VocOHdSnTx9J0unTpx36r1u3TiNGjFCvXr1uOq6vr68OHTrk0FauXLkiqhoAAJR2Lg1AVatWdfg+Y8YM1alTR+3atZMkBQQEOGxfvXq1HnnkEYWGht50XIvFUmBfAACA60rMNUBXr17V0qVLFRMTI4vFUmD7mTNntHbtWo0YMeKWY124cEHBwcGqWbOmunfvrj179ty0f05Ojmw2m8MHAADcv0pMAFq1apXOnTunYcOGFbp98eLF8vHxUc+ePW86TlhYmBYtWqQ1a9YoOTlZ5cqVU+vWrXX48OEb7pOQkCA/Pz/7Jygo6G6mAgAASjiLYRiGq4uQpE6dOsnDw0P/+Mc/Ct0eFhamDh06aP78+U6Nm5+fr8jISLVt21bz5s0rtE9OTo5ycnLs3202m4KCgpSdnS1fX1+njgegZEtPT1eTJk2UlpamyMhIV5cDoAjZbDb5+fnd1u+3S68Buu748ePauHGjPvroo0K3f/bZZzp06JBSUlKcHtvNzU3NmjW76QqQ1WqV1Wp1emwAAFA6lYhTYElJSapWrZq6detW6PaFCxeqSZMmatSokdNjG4ahjIwMVa9e/W7LBAAA9wmXB6D8/HwlJSVp6NChKlOm4IKUzWbTBx98oGeeeabQ/YcMGaK4uDj798mTJ+vTTz/Vd999p4yMDI0YMUIZGRn67W9/W2xzAAAApYvLT4Ft3LhRmZmZiomJKXT78uXLZRiGBgwYUOj2zMxMubn9N8edO3dOzz33nLKysuTn56fGjRtr+/btat68ebHUDwAASp8ScxF0SeLMRVQAShcuggbuX878frv8FBgAAMC9RgACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACmQwACAACm49IAFBISIovFUuDzu9/9TpI0bNiwAttatGhxy3FXrFih8PBwWa1WhYeHa+XKlcU9FQAAUIq4NADt2rVLp0+ftn82bNggSerTp4+9T+fOnR36/POf/7zpmKmpqerXr58GDx6svXv3avDgwerbt6927txZrHMBAAClRxlXHrxq1aoO32fMmKE6deqoXbt29jar1aqAgIDbHnPu3Lnq0KGD4uLiJElxcXHatm2b5s6dq+Tk5KIpHAAAlGouDUC/dvXqVS1dulR/+MMfZLFY7O1bt25VtWrVVKFCBbVr107Tpk1TtWrVbjhOamqqxowZ49DWqVMnzZ0794b75OTkKCcnx/7dZrPd+UQAFItLly7p4MGDdz3OgQMHHP5ZFMLCwuTl5VVk4wEofiUmAK1atUrnzp3TsGHD7G1dunRRnz59FBwcrKNHj2rChAl69NFHlZaWJqvVWug4WVlZ8vf3d2jz9/dXVlbWDY+dkJCgyZMnF8k8ABSPgwcPqkmTJkU23qBBg4psrLS0NEVGRhbZeACKX4kJQAsXLlSXLl0UGBhob+vXr5/93x988EE1bdpUwcHBWrt2rXr27HnDsX69giRJhmEUaPu1uLg4/eEPf7B/t9lsCgoKupNpACgmYWFhSktLu+txLl++rGPHjikkJESenp5FUNkvtQEoXUpEADp+/Lg2btyojz766Kb9qlevruDgYB0+fPiGfQICAgqs9pw9e7bAqtCvWa3WG64oASgZvLy8imyVpXXr1kUyDoDSq0Q8BygpKUnVqlVTt27dbtrvxx9/1IkTJ1S9evUb9mnZsqX9brLr1q9fr1atWhVJrQAAoPRzeQDKz89XUlKShg4dqjJl/rsgdeHCBb388stKTU3VsWPHtHXrVvXo0UNVqlTRU089Ze83ZMgQ+x1fkjR69GitX79eiYmJOnjwoBITE7Vx40bFxsbey2kBAIASzOUBaOPGjcrMzFRMTIxDu7u7u7766itFR0erfv36Gjp0qOrXr6/U1FT5+PjY+2VmZur06dP2761atdLy5cuVlJSkhx56SIsWLVJKSoqioqLu2ZwAAEDJZjEMw3B1ESWNzWaTn5+fsrOz5evr6+pyAADAbXDm99vlK0AAAAD3GgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYDgEIAACYThlXFwAA98rVq1f11ltv6ciRI6pTp45GjRolDw8PV5cFwAUIQABMYdy4cZozZ45yc3PtbWPHjtWYMWM0c+ZMF1YGwBU4BQbgvjdu3DjNmjVLlStX1t/+9jedPn1af/vb31S5cmXNmjVL48aNc3WJAO4xi2EYhquLKGlsNpv8/PyUnZ0tX19fV5cD4C5cvXpV3t7eqly5sk6ePKkyZf678J2bm6uaNWvqxx9/1MWLFzkdBpRyzvx+swIE4L721ltvKTc3V1OnTnUIP5JUpkwZTZkyRbm5uXrrrbdcVCEAVyAAAbivHTlyRJLUvXv3Qrdfb7/eD4A5EIAA3Nfq1KkjSfr4448L3X69/Xo/AObANUCF4Bog4P7BNUCAeXANEAD8fx4eHhozZozOnDmjmjVr6p133tGpU6f0zjvvqGbNmjpz5ozGjBlD+AFMhucAAbjvXX/Oz5w5czRy5Eh7e5kyZTR27FieAwSYEKfACsEpMOD+xJOggfubM7/fBKBCEIAAACh9uAYIAADgJghAAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdHgXWCGuPxzbZrO5uBIAAHC7rv9u385LLghAhTh//rwkKSgoyMWVAAAAZ50/f15+fn437cO7wAqRn5+vU6dOycfHRxaLxdXlAChCNptNQUFBOnHiBO/6A+4zhmHo/PnzCgwMlJvbza/yIQABMBVedgxA4iJoAABgQgQgAABgOgQgAKZitVr12muvyWq1uroUAC7ENUAAAMB0WAECAACmQwACAACmQwACAACmQwACAACmQwACYArbt29Xjx49FBgYKIvFolWrVrm6JAAuRAACYAoXL15Uo0aN9Oabb7q6FAAlAC9DBWAKXbp0UZcuXVxdBoASghUgAABgOgQgAABgOgQgAABgOgQgAABgOgQgAABgOtwFBsAULly4oG+//db+/ejRo8rIyFClSpVUq1YtF1YGwBV4GzwAU9i6daseeeSRAu1Dhw7VokWL7n1BAFyKAAQAAEyHa4AAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAAAIDpEIAA4C6EhIRo7ty5ri4DgJMIQADu2rBhw2SxWGSxWFS2bFmFhobq5Zdf1sWLF11dWgGTJk3Sww8/7PR+ixYtUoUKFQq079q1S88999zdFwbgnuJlqACKROfOnZWUlKRr167ps88+0zPPPKOLFy/q7bffdmocwzCUl5enMmVKx3+eqlat6uoSANwBVoAAFAmr1aqAgAAFBQVp4MCBevrpp7Vq1SoZhqGZM2cqNDRUnp6eatSokT788EP7flu3bpXFYtGnn36qpk2bymq16rPPPlP79u31wgsvKDY2VhUrVpS/v7/eeecdXbx4UcOHD5ePj4/q1KmjdevW2ccqbJVm1apVslgs9u2TJ0/W3r177StW11+EOnv2bEVERMjb21tBQUEaNWqULly4YK9x+PDhys7Otu83adIkSQVPgWVmZio6Olrly5eXr6+v+vbtqzNnzti3X1+BWrJkiUJCQuTn56f+/fvr/Pnz9j4ffvihIiIi5OnpqcqVK+vxxx8vkatpQGlGAAJQLDw9PXXt2jXFx8crKSlJb7/9tvbt26cxY8Zo0KBB2rZtm0P/cePGKSEhQQcOHNBDDz0kSVq8eLGqVKmif//733rhhRf0/PPPq0+fPmrVqpXS09PVqVMnDR48WJcuXbqtmvr166eXXnpJDRs21OnTp3X69Gn169dPkuTm5qZ58+bp66+/1uLFi7V582aNGzdOktSqVSvNnTtXvr6+9v1efvnlAuMbhqEnn3xSP/30k7Zt26YNGzboyJEj9mNcd+TIEa1atUoff/yxPv74Y23btk0zZsyQJJ0+fVoDBgxQTEyMDhw4oK1bt6pnz57ivdVAETMA4C4NHTrUiI6Otn/fuXOnUblyZaN3795GuXLljM8//9yh/4gRI4wBAwYYhmEYW7ZsMSQZq1atcujTrl07o02bNvbvubm5hre3tzF48GB72+nTpw1JRmpqqmEYhpGUlGT4+fk5jLNy5Urj1/+pe+2114xGjRrdck7vv/++UblyZfv3wsY2DMMIDg425syZYxiGYaxfv95wd3c3MjMz7dv37dtnSDL+/e9/24/v5eVl2Gw2e5+xY8caUVFRhmEYRlpamiHJOHbs2C1rBHDnSsdJdgAl3scff6zy5csrNzdX165dU3R0tF5++WV9+OGH6tChg0Pfq1evqnHjxg5tTZs2LTDm9ZUgSXJ3d1flypUVERFhb/P395cknT179q7r37Jli6ZPn679+/fLZrMpNzdXV65c0cWLF+Xt7X1bYxw4cEBBQUEKCgqyt4WHh6tChQo6cOCAmjVrJumX02Y+Pj72PtWrV7fPoVGjRnrssccUERGhTp06qWPHjurdu7cqVqx413ME8F+cAgNQJB555BFlZGTo0KFDunLlij766CP7trVr1yojI8P+2b9/v8N1QJIKDRlly5Z1+H79LrNff5ek/Px8Sb+cxjL+51TRtWvXbln78ePH1bVrVz344INasWKF0tLS9Je//OW297/OMAx7TTdrL2xe1+fg7u6uDRs2aN26dQoPD9f8+fP1wAMP6OjRo7ddB4BbIwABKBLe3t6qW7eugoOD7T/w4eHhslqtyszMVN26dR0+v14lKSpVq1bV+fPnHS4YzsjIcOjj4eGhvLw8h7bdu3crNzdXb7zxhlq0aKH69evr1KlTt9zvf4WHhyszM1MnTpywt+3fv1/Z2dlq0KDBbc/DYrGodevWmjx5svbs2SMPDw+tXLnytvcHcGucAgNQbHx8fPTyyy9rzJgxys/PV5s2bWSz2fT555+rfPnyGjp0aJEeLyoqSl5eXnr11Vf1wgsv6N///rf9Lq/rQkJCdPToUWVkZKhmzZr2u8lyc3M1f/589ejRQ//617+0YMGCAvtduHBBmzZtUqNGjeTl5SUvLy+HPo8//rgeeughPf3005o7d65yc3M1atQotWvXrtBTfIXZuXOnNm3apI4dO6patWrauXOnfvjhB6cCFIBbYwUIQLF6/fXXNXHiRCUkJKhBgwbq1KmT/vGPf6h27dpFfqxKlSpp6dKl+uc//6mIiAglJyfbb1e/rlevXurcubMeeeQRVa1aVcnJyXr44Yc1e/ZsJSYm6sEHH9SyZcuUkJDgsF+rVq3029/+Vv369VPVqlU1c+bMAse3WCxatWqVKlasqLZt2+rxxx9XaGioUlJSbnsOvr6+2r59u7p27ar69esrPj5eb7zxhrp06XJHfxMAhbMY/3vCHAAA4D7HChAAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADAdAhAAADCd/wdw9N7nTsNTVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "now = datetime.today()\n",
    "timestamp_str = now.strftime(\"%Y-%m-%d_%H-%M-%S-%f\")\n",
    "output_frame = pd.DataFrame(data={'Validation_Participants': samples, 'Accuracies': accuracies})\n",
    "\n",
    "plt.boxplot(accuracies)\n",
    "plt.xlabel(\"Permutations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "mean_accuracy = numpy.mean(accuracies)\n",
    "plt.text(1.15, mean_accuracy, f\"Mean: {mean_accuracy:.2f}\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('output/' + timestamp_str + '_boxplot.png')\n",
    "output_frame.to_csv('output/' + timestamp_str + '_run_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d27d10a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
